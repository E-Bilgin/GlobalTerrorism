# -*- coding: utf-8 -*-
"""Final_Reg_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fnkei5dF_HSsBMP2lgDdUdkSCtFVUTOm
"""

#importing libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from google.colab import files 
uploaded = files.upload()

attack = pd.read_csv('globalterrorismdb.csv',encoding='ISO-8859-1', low_memory=False)
attack.rename(columns={'iyear':'Year','imonth':'Month','iday':'Day','country_txt':'Country','region_txt':'Region','attacktype1_txt':'AttackType','target1':'Target','nkill':'Killed','nwound':'Wounded','summary':'Summary','gname':'Group','targtype1_txt':'Target_type','weaptype1_txt':'Weapon_type','motive':'Motive'},inplace=True)
attack = attack[['Year','Month','Day','Country','Region','city','latitude','longitude','AttackType','Killed','Wounded','Target','Summary','Group','Target_type','Weapon_type','Motive']]
attack['casualities'] = attack['Killed'] + attack['Wounded']

# Selecting top 15 countries
attack_most_freq = attack[(attack.Country == 'Iraq') | (attack.Country == 'Pakistan') | (attack.Country == 'Afghanistan') | (attack.Country == 'India') | (attack.Country == 'Colombia') | (attack.Country == 'Philippines') | (attack.Country == 'Peru') | (attack.Country == 'El Salvador') | (attack.Country == 'United Kingdom') | (attack.Country == 'Turkey') | (attack.Country == 'Somalia') | (attack.Country == 'Nigeria') | (attack.Country == 'Thailand') | (attack.Country == 'Yemen') | (attack.Country == 'Spain')]
attack_most_freq = attack_most_freq.drop(["Summary","Motive"],axis = 1)
#attack_most_freq.mean()
attack_most_freq = attack_most_freq.fillna(attack_most_freq.mean())
#attack_most_freq = attack_most_freq.dropna()
attack_most_freq.isnull().sum()

attack_most_freq = attack_most_freq.dropna()
attack_most_freq.isnull().sum()
#attack_most_freq.shape

attack_most_freq

attack_most_freq_country = pd.get_dummies(attack_most_freq['Country'])
df_new_1 = pd.concat([attack_most_freq, attack_most_freq_country], axis=1)
# Create a set of dummy variables from the attack_type variable
attack_most_freq_attackType = pd.get_dummies(attack_most_freq['AttackType'])
#df_new_2 = pd.concat([attack_most_freq_country, attack_most_freq_attackType], axis=1)
df_new_2 = df_new_1.join(attack_most_freq_attackType)
attack_most_freq_Region = pd.get_dummies(attack_most_freq['Region'])
df_new_3 = df_new_2.join(attack_most_freq_Region)
df_new_3 = df_new_3.drop(["city","Target","Group"],axis = 1)
df_new_4 = df_new_3.drop(["Target_type","Weapon_type"],axis = 1)
df_new_4.shape

df_new_4

y = df_new_4['casualities']
df_new_5 = df_new_4.drop('casualities',axis=1)
#X = df_new_5

df_new_6 = df_new_5.drop(["Country","AttackType","Region"],axis = 1)
X = df_new_6

# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X = X.astype('float64')
X = sc.fit_transform(X)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import GridSearchCV
mlp = MLPRegressor()
parameters = {'activation' : ['tanh'],
              'solver': ['sgd'],
              'hidden_layer_sizes':np.arange(1, 12)}

mlpregressor = GridSearchCV(mlp, parameters, scoring='neg_mean_squared_error', cv=5)
mlpregressor.fit(X_train, y_train)

print(mlpregressor.best_params_)
print(mlpregressor.best_score_)

from sklearn.metrics import mean_squared_error

y_pred = mlpregressor.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print('MSE on MLP model =', mse)
mse_arr = []
mse_arr.append(mse)
mse_arr
mlp_mse = mse

from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()

MSEs = cross_val_score(lin_reg, X_train, y_train, scoring='neg_mean_squared_error', cv=5)

lin_reg.fit(X_train, y_train)

mean_MSE = np.mean(MSEs)

mean_MSE

from sklearn.metrics import mean_squared_error

y_pred = lin_reg.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print('MSE on linear model =', mse)
mse_arr.append(mse)
mse_arr
linear_mse = mse

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import Ridge

ridge = Ridge()

parameters = {'alpha': [1e-3, 1e-2, 1, 5, 10, 20, 40, 80, 160]}

ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=5)

ridge_regressor.fit(X_train, y_train)

print(ridge_regressor.best_params_)
print(ridge_regressor.best_score_)

y_pred = ridge_regressor.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print('MSE on ridge model =', mse)
mse_arr.append(mse)
mse_arr
ridge_mse = mse

from sklearn.linear_model import Lasso

lasso = Lasso()

parameters = {'alpha': [1e-3, 1e-2, 1, 5, 10, 20, 40, 80, 160]}

lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=5)

lasso_regressor.fit(X_train, y_train)

print(lasso_regressor.best_params_)
print(lasso_regressor.best_score_)

y_pred = lasso_regressor.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print('MSE on lasso model =', mse)
mse_arr.append(mse)
mse_arr
lasso_mse = mse

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor()

parameters = {'max_depth': range(3,5),
            'n_estimators': (40, 50,),}

rfr = GridSearchCV(rf, parameters, scoring='neg_mean_squared_error', cv=5)

rfr.fit(X_train, y_train)

print(rfr.best_params_)
print(rfr.best_score_)

y_pred = rfr.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print('MSE on random_forset model =', mse)
mse_arr.append(mse)
mse_arr
rf_mse = mse

mse = []
mse.append(mse_arr[0])
mse.append(mse_arr[2])
mse.append(mse_arr[3])
mse.append(mse_arr[4])
col={'Mean Square Error': mse}
models=['MLP', 'Ridge', 'Lasso', 'Random Forset']
df = pd.DataFrame(data=col, index=models)
df

df.plot(kind='bar')